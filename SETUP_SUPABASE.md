# Setup Supabase Database Schema

Per completare l'implementazione dell'architettura `newintegration.md`, Ã¨ necessario applicare lo schema del database a Supabase.

## ğŸ”§ **Passo 1: Accedi al Dashboard Supabase**

1. Vai su [https://supabase.com/dashboard](https://supabase.com/dashboard)
2. Accedi al progetto `umflteqpkosigldvitaa` 
3. Vai alla sezione **SQL Editor** nel menu laterale

## ğŸ“‹ **Passo 2: Applica lo Schema Database**

**âš ï¸ Se hai giÃ  tentato di applicare lo schema e hai ricevuto errori "relation already exists":**

1. Clicca su "New Query" nel SQL Editor
2. Copia tutto il contenuto del file `supabase-reset-and-create.sql` 
3. Incolla il contenuto nell'editor SQL
4. Clicca su "Run" per eseguire lo script

**âœ… Se Ã¨ la prima volta che applichi lo schema:**

1. Clicca su "New Query" nel SQL Editor
2. Copia tutto il contenuto del file `supabase-schema-complete.sql`
3. Incolla il contenuto nell'editor SQL
4. Clicca su "Run" per eseguire lo script

**Il file `supabase-reset-and-create.sql` farÃ  un reset completo e ricreerÃ  tutto da zero, risolvendo eventuali conflitti.**

Lo script creerÃ :
- âœ… 12 tabelle principali (workspaces, jobs, documents, artifacts, etc.)
- âœ… Indici per le performance
- âœ… Row Level Security (RLS) policies
- âœ… Storage buckets (pdfs, exports)
- âœ… Workspace e profili di default
- âœ… Trigger per updated_at

## ğŸ§ª **Passo 3: Verifica Setup**

Dopo aver applicato lo schema, puoi verificare che tutto funzioni:

```bash
node test_supabase_connection.js
```

Dovresti vedere:
```
âœ… Workspaces table accessible
âœ… Profiles table accessible  
âœ… Storage accessible
âœ… Signed upload URL created successfully
ğŸ‰ Supabase connection test completed successfully!
```

## ğŸš€ **Passo 4: Test Frontend**

1. Il dev server dovrebbe essere su `http://localhost:5175`
2. Vai a `/dashboard/new-comparison`
3. Carica 2 PDF di test
4. Avvia il processing
5. Verifica che il sistema generi una tabella di confronto

## ğŸ“Š **Struttura Dati Creata**

Il database includerÃ :

### **Tabelle Core**
- `workspaces` - Multi-tenancy
- `jobs` - Job orchestration  
- `documents` - File metadata
- `artifacts` - Parsed content (Tabula/OCR)
- `extractions_raw` - LangChain output
- `extractions_norm` - Normalized values
- `results` - Final comparison tables

### **Domain Profiles**
- `semiconductors` v1.0 (6 campi: model, power, voltage, frequency, temp, package)
- `api_sdk` v1.0 (6 campi: name, version, auth, rate_limit, latency, uptime)

### **Storage Buckets**
- `pdfs` - PDF uploads (private)
- `exports` - CSV/XLSX exports (private)

## ğŸ” **Troubleshooting**

**Error: "Could not find table"**
- Lo schema non Ã¨ stato applicato correttamente
- Riprova ad eseguire `supabase-schema-complete.sql`

**Error: "Invalid URL"**  
- Verifica che le variabili in `.env.local` siano corrette:
  ```
  VITE_SUPABASE_URL=https://umflteqpkosigldvitaa.supabase.co
  VITE_SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIs...
  ```

**Upload fails**
- Verifica che i bucket `pdfs` siano stati creati
- Controlla le RLS policies nel dashboard

## âœ… **Risultato Finale**

Una volta completato il setup, avrai:

- ğŸ—ï¸ **API Gateway completo** con orchestrazione async
- ğŸ“¤ **Upload sicuro** con signed URLs
- ğŸ§  **Pipeline di processing** mock (Tabula + OCR + LangChain)  
- ğŸ“Š **Generazione tabelle** di confronto realistic
- ğŸ’¾ **Database strutturato** secondo `newintegration.md`
- ğŸ”’ **Security** con RLS e multi-tenancy

Il sistema sarÃ  pronto per l'integrazione con i veri servizi di processing (Tabula, Google Cloud OCR, LangChain) quando necessario.